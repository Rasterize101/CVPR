{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jitbh\\OneDrive\\Documents\\GitHub\\CVPR\\test2_vanishHorizons.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/test2_vanishHorizons.ipynb#ch0000000?line=527'>528</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m warped_img\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/test2_vanishHorizons.ipynb#ch0000000?line=528'>529</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m./fd_jpg/IMG_9129.jpg\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m0\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/test2_vanishHorizons.ipynb#ch0000000?line=529'>530</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(image, cv2\u001b[39m.\u001b[39;49mCOLOR_GRAY2BGR)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/test2_vanishHorizons.ipynb#ch0000000?line=530'>531</a>\u001b[0m edgelets1 \u001b[39m=\u001b[39m compute_edgelets(image)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/test2_vanishHorizons.ipynb#ch0000000?line=531'>532</a>\u001b[0m vis_edgelets(image, edgelets1) \u001b[39m# Visualize the edgelets\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Start writing code here...\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#images 9125 and 9127\n",
    "\n",
    "image1path =r'C:\\Users\\jitbh\\OneDrive\\Desktop\\DSC_0714.JPG'\n",
    "\n",
    "image2path =r'C:\\Users\\jitbh\\OneDrive\\Desktop\\DSC_0715.JPG'\n",
    "\n",
    "\n",
    "img1 = cv.imread(image1path)\n",
    "img1 = cv.resize(img1, (1368, 912))\n",
    "\n",
    "\n",
    "img2 = cv.imread(image2path)\n",
    "img2 = cv.resize(img2, (1368, 912))\n",
    "\n",
    "\n",
    "\"\"\"Automated Rectification of Image.\n",
    "References\n",
    "----------\n",
    "1.  Chaudhury, Krishnendu, Stephen DiVerdi, and Sergey Ioffe.\n",
    "    \"Auto-rectification of user photos.\" 2014 IEEE International Conference on\n",
    "    Image Processing (ICIP). IEEE, 2014.\n",
    "2.  Bazin, Jean-Charles, and Marc Pollefeys. \"3-line RANSAC for orthogonal\n",
    "    vanishing point detection.\" 2012 IEEE/RSJ International Conference on\n",
    "    Intelligent Robots and Systems. IEEE, 2012.\n",
    "\"\"\"\n",
    "from skimage import feature, color, transform, io\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "def compute_edgelets(image, sigma=3):\n",
    "    \"\"\"Create edgelets as in the paper.\n",
    "    Uses canny edge detection and then finds (small) lines using probabilstic\n",
    "    hough transform as edgelets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ndarray\n",
    "        Image for which edgelets are to be computed.\n",
    "    sigma: float\n",
    "        Smoothing to be used for canny edge detection.\n",
    "    Returns\n",
    "    -------\n",
    "    locations: ndarray of shape (n_edgelets, 2)\n",
    "        Locations of each of the edgelets.\n",
    "    directions: ndarray of shape (n_edgelets, 2)\n",
    "        Direction of the edge (tangent) at each of the edgelet.\n",
    "    strengths: ndarray of shape (n_edgelets,)\n",
    "        Length of the line segments detected for the edgelet.\n",
    "    \"\"\"\n",
    "    gray_img = color.rgb2gray(image)\n",
    "    edges = feature.canny(gray_img, sigma)\n",
    "    lines = transform.probabilistic_hough_line(edges, line_length=3,\n",
    "                                               line_gap=2)\n",
    "\n",
    "    locations = []\n",
    "    directions = []\n",
    "    strengths = []\n",
    "\n",
    "    for p0, p1 in lines:\n",
    "        p0, p1 = np.array(p0), np.array(p1)\n",
    "        locations.append((p0 + p1) / 2)\n",
    "        directions.append(p1 - p0)\n",
    "        strengths.append(np.linalg.norm(p1 - p0))\n",
    "\n",
    "    # convert to numpy arrays and normalize\n",
    "    locations = np.array(locations)\n",
    "    directions = np.array(directions)\n",
    "    strengths = np.array(strengths)\n",
    "\n",
    "    directions = np.array(directions) / \\\n",
    "        np.linalg.norm(directions, axis=1)[:, np.newaxis]\n",
    "\n",
    "    return (locations, directions, strengths)\n",
    "\n",
    "\n",
    "def edgelet_lines(edgelets):\n",
    "    \"\"\"Compute lines in homogenous system for edglets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    Returns\n",
    "    -------\n",
    "    lines: ndarray of shape (n_edgelets, 3)\n",
    "        Lines at each of edgelet locations in homogenous system.\n",
    "    \"\"\"\n",
    "    locations, directions, _ = edgelets\n",
    "    normals = np.zeros_like(directions)\n",
    "    normals[:, 0] = directions[:, 1]\n",
    "    normals[:, 1] = -directions[:, 0]\n",
    "    p = -np.sum(locations * normals, axis=1)\n",
    "    lines = np.concatenate((normals, p[:, np.newaxis]), axis=1)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def compute_votes(edgelets, model, threshold_inlier=5):\n",
    "    \"\"\"Compute votes for each of the edgelet against a given vanishing point.\n",
    "    Votes for edgelets which lie inside threshold are same as their strengths,\n",
    "    otherwise zero.\n",
    "    Parameters\n",
    "    ----------\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    model: ndarray of shape (3,)\n",
    "        Vanishing point model in homogenous cordinate system.\n",
    "    threshold_inlier: float\n",
    "        Threshold to be used for computing inliers in degrees. Angle between\n",
    "        edgelet direction and line connecting the  Vanishing point model and\n",
    "        edgelet location is used to threshold.\n",
    "    Returns\n",
    "    -------\n",
    "    votes: ndarry of shape (n_edgelets,)\n",
    "        Votes towards vanishing point model for each of the edgelet.\n",
    "    \"\"\"\n",
    "    vp = model[:2] / model[2]\n",
    "\n",
    "    locations, directions, strengths = edgelets\n",
    "\n",
    "    est_directions = locations - vp\n",
    "    dot_prod = np.sum(est_directions * directions, axis=1)\n",
    "    abs_prod = np.linalg.norm(directions, axis=1) * \\\n",
    "        np.linalg.norm(est_directions, axis=1)\n",
    "    abs_prod[abs_prod == 0] = 1e-5\n",
    "\n",
    "    cosine_theta = dot_prod / abs_prod\n",
    "    theta = np.arccos(np.abs(cosine_theta))\n",
    "\n",
    "    theta_thresh = threshold_inlier * np.pi / 180\n",
    "    return (theta < theta_thresh) * strengths\n",
    "\n",
    "\n",
    "def ransac_vanishing_point(edgelets, num_ransac_iter=2000, threshold_inlier=5):\n",
    "    \"\"\"Estimate vanishing point using Ransac.\n",
    "    Parameters\n",
    "    ----------\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    num_ransac_iter: int\n",
    "        Number of iterations to run ransac.\n",
    "    threshold_inlier: float\n",
    "        threshold to be used for computing inliers in degrees.\n",
    "    Returns\n",
    "    -------\n",
    "    best_model: ndarry of shape (3,)\n",
    "        Best model for vanishing point estimated.\n",
    "    Reference\n",
    "    ---------\n",
    "    Chaudhury, Krishnendu, Stephen DiVerdi, and Sergey Ioffe.\n",
    "    \"Auto-rectification of user photos.\" 2014 IEEE International Conference on\n",
    "    Image Processing (ICIP). IEEE, 2014.\n",
    "    \"\"\"\n",
    "    locations, directions, strengths = edgelets\n",
    "    lines = edgelet_lines(edgelets)\n",
    "\n",
    "    num_pts = strengths.size\n",
    "\n",
    "    arg_sort = np.argsort(-strengths)\n",
    "    first_index_space = arg_sort[:num_pts // 5]\n",
    "    second_index_space = arg_sort[:num_pts // 2]\n",
    "\n",
    "    best_model = None\n",
    "    best_votes = np.zeros(num_pts)\n",
    "\n",
    "    for ransac_iter in range(num_ransac_iter):\n",
    "        ind1 = np.random.choice(first_index_space)\n",
    "        ind2 = np.random.choice(second_index_space)\n",
    "\n",
    "        l1 = lines[ind1]\n",
    "        l2 = lines[ind2]\n",
    "\n",
    "        current_model = np.cross(l1, l2)\n",
    "\n",
    "        if np.sum(current_model**2) < 1 or current_model[2] == 0:\n",
    "            # reject degenerate candidates\n",
    "            continue\n",
    "\n",
    "        current_votes = compute_votes(\n",
    "            edgelets, current_model, threshold_inlier)\n",
    "\n",
    "        if current_votes.sum() > best_votes.sum():\n",
    "            best_model = current_model\n",
    "            best_votes = current_votes\n",
    "            logging.info(\"Current best model has {} votes at iteration {}\".format(\n",
    "                current_votes.sum(), ransac_iter))\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def ransac_3_line(edgelets, focal_length, num_ransac_iter=2000,\n",
    "                  threshold_inlier=5):\n",
    "    \"\"\"Estimate orthogonal vanishing points using 3 line Ransac algorithm.\n",
    "    Assumes camera has been calibrated and its focal length is known.\n",
    "    Parameters\n",
    "    ----------\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    focal_length: float\n",
    "        Focal length of the camera used.\n",
    "    num_ransac_iter: int\n",
    "        Number of iterations to run ransac.\n",
    "    threshold_inlier: float\n",
    "        threshold to be used for computing inliers in degrees.\n",
    "    Returns\n",
    "    -------\n",
    "    vp1: ndarry of shape (3,)\n",
    "        Estimated model for first vanishing point.\n",
    "    vp2: ndarry of shape (3,)\n",
    "        Estimated model for second vanishing point, which is orthogonal to\n",
    "        first vanishing point.\n",
    "    Reference\n",
    "    ---------\n",
    "    Bazin, Jean-Charles, and Marc Pollefeys. \"3-line RANSAC for orthogonal\n",
    "    vanishing point detection.\" 2012 IEEE/RSJ International Conference on\n",
    "    Intelligent Robots and Systems. IEEE, 2012.\n",
    "    \"\"\"\n",
    "    locations, directions, strengths = edgelets\n",
    "    lines = edgelet_lines(edgelets)\n",
    "\n",
    "    num_pts = strengths.size\n",
    "\n",
    "    arg_sort = np.argsort(-strengths)\n",
    "    first_index_space = arg_sort[:num_pts // 5]\n",
    "    second_index_space = arg_sort[:num_pts // 5]\n",
    "    third_index_space = arg_sort[:num_pts // 2]\n",
    "\n",
    "    best_model = (None, None)\n",
    "    best_votes = 0\n",
    "\n",
    "    for ransac_iter in range(num_ransac_iter):\n",
    "        ind1 = np.random.choice(first_index_space)\n",
    "        ind2 = np.random.choice(second_index_space)\n",
    "        ind3 = np.random.choice(third_index_space)\n",
    "\n",
    "        l1 = lines[ind1]\n",
    "        l2 = lines[ind2]\n",
    "        l3 = lines[ind3]\n",
    "\n",
    "        vp1 = np.cross(l1, l2)\n",
    "        # The vanishing line polar to v1\n",
    "        h = np.dot(vp1, [1 / focal_length*2, 1 / focal_length*2, 1])\n",
    "        vp2 = np.cross(h, l3)\n",
    "\n",
    "        if np.sum(vp1**2) < 1 or vp1[2] == 0:\n",
    "            # reject degenerate candidates\n",
    "            continue\n",
    "\n",
    "        if np.sum(vp2**2) < 1 or vp2[2] == 0:\n",
    "            # reject degenerate candidates\n",
    "            continue\n",
    "\n",
    "        vp1_votes = compute_votes(edgelets, vp1, threshold_inlier)\n",
    "        vp2_votes = compute_votes(edgelets, vp2, threshold_inlier)\n",
    "        current_votes = (vp1_votes > 0).sum() + (vp2_votes > 0).sum()\n",
    "\n",
    "        if current_votes > best_votes:\n",
    "            best_model = (vp1, vp2)\n",
    "            best_votes = current_votes\n",
    "            logging.info(\"Current best model has {} votes at iteration {}\".format(\n",
    "                current_votes, ransac_iter))\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def reestimate_model(model, edgelets, threshold_reestimate=5):\n",
    "    \"\"\"Reestimate vanishing point using inliers and least squares.\n",
    "    All the edgelets which are within a threshold are used to reestimate model\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: ndarry of shape (3,)\n",
    "        Vanishing point model in homogenous coordinates which is to be\n",
    "        reestimated.\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "        All edgelets from which inliers will be computed.\n",
    "    threshold_inlier: float\n",
    "        threshold to be used for finding inlier edgelets.\n",
    "    Returns\n",
    "    -------\n",
    "    restimated_model: ndarry of shape (3,)\n",
    "        Reestimated model for vanishing point in homogenous coordinates.\n",
    "    \"\"\"\n",
    "    locations, directions, strengths = edgelets\n",
    "\n",
    "    inliers = compute_votes(edgelets, model, threshold_reestimate) > 0\n",
    "    locations = locations[inliers]\n",
    "    directions = directions[inliers]\n",
    "    strengths = strengths[inliers]\n",
    "\n",
    "    lines = edgelet_lines((locations, directions, strengths))\n",
    "\n",
    "    a = lines[:, :2]\n",
    "    b = -lines[:, 2]\n",
    "    est_model = np.linalg.lstsq(a, b)[0]\n",
    "    return np.concatenate((est_model, [1.]))\n",
    "\n",
    "\n",
    "def remove_inliers(model, edgelets, threshold_inlier=10):\n",
    "    \"\"\"Remove all inlier edglets of a given model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: ndarry of shape (3,)\n",
    "        Vanishing point model in homogenous coordinates which is to be\n",
    "        reestimated.\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    threshold_inlier: float\n",
    "        threshold to be used for finding inlier edgelets.\n",
    "    Returns\n",
    "    -------\n",
    "    edgelets_new: tuple of ndarrays\n",
    "        All Edgelets except those which are inliers to model.\n",
    "    \"\"\"\n",
    "    inliers = compute_votes(edgelets, model, 10) > 0\n",
    "    locations, directions, strengths = edgelets\n",
    "    locations = locations[~inliers]\n",
    "    directions = directions[~inliers]\n",
    "    strengths = strengths[~inliers]\n",
    "    edgelets = (locations, directions, strengths)\n",
    "    return edgelets\n",
    "\n",
    "\n",
    "def compute_homography_and_warp(image, vp1, vp2, clip=True, clip_factor=3):\n",
    "    \"\"\"Compute homography from vanishing points and warp the image.\n",
    "    It is assumed that vp1 and vp2 correspond to horizontal and vertical\n",
    "    directions, although the order is not assumed.\n",
    "    Firstly, projective transform is computed to make the vanishing points go\n",
    "    to infinty so that we have a fronto parellel view. Then,Computes affine\n",
    "    transfom  to make axes corresponding to vanishing points orthogonal.\n",
    "    Finally, Image is translated so that the image is not missed. Note that\n",
    "    this image can be very large. `clip` is provided to deal with this.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ndarray\n",
    "        Image which has to be wrapped.\n",
    "    vp1: ndarray of shape (3, )\n",
    "        First vanishing point in homogenous coordinate system.\n",
    "    vp2: ndarray of shape (3, )\n",
    "        Second vanishing point in homogenous coordinate system.\n",
    "    clip: bool, optional\n",
    "        If True, image is clipped to clip_factor.\n",
    "    clip_factor: float, optional\n",
    "        Proportion of image in multiples of image size to be retained if gone\n",
    "        out of bounds after homography.\n",
    "    Returns\n",
    "    -------\n",
    "    warped_img: ndarray\n",
    "        Image warped using homography as described above.\n",
    "    \"\"\"\n",
    "    # Find Projective Transform\n",
    "    vanishing_line = np.cross(vp1, vp2)\n",
    "    H = np.eye(3)\n",
    "    H[2] = vanishing_line / vanishing_line[2]\n",
    "    H = H / H[2, 2]\n",
    "\n",
    "    # Find directions corresponding to vanishing points\n",
    "    v_post1 = np.dot(H, vp1)\n",
    "    v_post2 = np.dot(H, vp2)\n",
    "    v_post1 = v_post1 / np.sqrt(v_post1[0]*2 + v_post1[1]*2)\n",
    "    v_post2 = v_post2 / np.sqrt(v_post2[0]*2 + v_post2[1]*2)\n",
    "\n",
    "    directions = np.array([[v_post1[0], -v_post1[0], v_post2[0], -v_post2[0]],\n",
    "                           [v_post1[1], -v_post1[1], v_post2[1], -v_post2[1]]])\n",
    "\n",
    "    thetas = np.arctan2(directions[0], directions[1])\n",
    "\n",
    "    # Find direction closest to horizontal axis\n",
    "    h_ind = np.argmin(np.abs(thetas))\n",
    "\n",
    "    # Find positve angle among the rest for the vertical axis\n",
    "    if h_ind // 2 == 0:\n",
    "        v_ind = 2 + np.argmax([thetas[2], thetas[3]])\n",
    "    else:\n",
    "        v_ind = np.argmax([thetas[2], thetas[3]])\n",
    "\n",
    "    A1 = np.array([[directions[0, v_ind], directions[0, h_ind], 0],\n",
    "                   [directions[1, v_ind], directions[1, h_ind], 0],\n",
    "                   [0, 0, 1]])\n",
    "    # Might be a reflection. If so, remove reflection.\n",
    "    if np.linalg.det(A1) < 0:\n",
    "        A1[:, 0] = -A1[:, 0]\n",
    "\n",
    "    A = np.linalg.inv(A1)\n",
    "\n",
    "    # Translate so that whole of the image is covered\n",
    "    inter_matrix = np.dot(A, H)\n",
    "\n",
    "    cords = np.dot(inter_matrix, [[0, 0, image.shape[1], image.shape[1]],\n",
    "                                  [0, image.shape[0], 0, image.shape[0]],\n",
    "                                  [1, 1, 1, 1]])\n",
    "    cords = cords[:2] / cords[2]\n",
    "\n",
    "    tx = min(0, cords[0].min())\n",
    "    ty = min(0, cords[1].min())\n",
    "\n",
    "    max_x = cords[0].max() - tx\n",
    "    max_y = cords[1].max() - ty\n",
    "\n",
    "    if clip:\n",
    "        # These might be too large. Clip them.\n",
    "        max_offset = max(image.shape) * clip_factor / 2\n",
    "        tx = max(tx, -max_offset)\n",
    "        ty = max(ty, -max_offset)\n",
    "\n",
    "        max_x = min(max_x, -tx + max_offset)\n",
    "        max_y = min(max_y, -ty + max_offset)\n",
    "\n",
    "    max_x = int(max_x)\n",
    "    max_y = int(max_y)\n",
    "\n",
    "    T = np.array([[1, 0, -tx],\n",
    "                  [0, 1, -ty],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    final_homography = np.dot(T, inter_matrix)\n",
    "\n",
    "    warped_img = transform.warp(image, np.linalg.inv(final_homography),\n",
    "                                output_shape=(max_y, max_x))\n",
    "    return warped_img\n",
    "\n",
    "\n",
    "def vis_edgelets(image, edgelets, show=True):\n",
    "    \"\"\"Helper function to visualize edgelets.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    locations, directions, strengths = edgelets\n",
    "    for i in range(locations.shape[0]):\n",
    "        xax = [locations[i, 0] - directions[i, 0] * strengths[i] / 2,\n",
    "               locations[i, 0] + directions[i, 0] * strengths[i] / 2]\n",
    "        yax = [locations[i, 1] - directions[i, 1] * strengths[i] / 2,\n",
    "               locations[i, 1] + directions[i, 1] * strengths[i] / 2]\n",
    "\n",
    "        plt.plot(xax, yax, 'r-')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def vis_model(image, model, show=True):\n",
    "    \"\"\"Helper function to visualize computed model.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    edgelets = compute_edgelets(image)\n",
    "    locations, directions, strengths = edgelets\n",
    "    inliers = compute_votes(edgelets, model, 10) > 0\n",
    "\n",
    "    edgelets = (locations[inliers], directions[inliers], strengths[inliers])\n",
    "    locations, directions, strengths = edgelets\n",
    "    vis_edgelets(image, edgelets, False)\n",
    "    vp = model / model[2]\n",
    "    for i in range(locations.shape[0]):\n",
    "        xax = [locations[i, 0], vp[0]]\n",
    "        yax = [locations[i, 1], vp[1]]\n",
    "        plt.plot(xax, yax, 'b-.')\n",
    "    plt.plot([0,vp[0]+150],[vp[1],vp[1]],'-r',linewidth=3,label='Horizon Line')\n",
    "    plt.plot(vp[0], vp[1], 'ro', label='Vanishing Point')\n",
    "    plt.legend()\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def rectify_image(image, clip_factor=6, algorithm='independent',\n",
    "                  reestimate=False):\n",
    "    \"\"\"Rectified image with vanishing point computed using ransac.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ndarray\n",
    "        Image which has to be rectified.\n",
    "    clip_factor: float, optional\n",
    "        Proportion of image in multiples of image size to be retained if gone\n",
    "        out of bounds after homography.\n",
    "    algorithm: one of {'3-line', 'independent'}\n",
    "        independent ransac algorithm finds the orthogonal vanishing points by\n",
    "        applying ransac twice.\n",
    "        3-line algorithm finds the orthogonal vanishing points together, but\n",
    "        assumes knowledge of focal length.\n",
    "    reestimate: bool\n",
    "        If ransac results are to be reestimated using least squares with\n",
    "        inlers. Turn this off if getting bad results.\n",
    "    Returns\n",
    "    -------\n",
    "    warped_img: ndarray\n",
    "        Rectified image.\n",
    "    \"\"\"\n",
    "    if type(image) is not np.ndarray:\n",
    "        image = io.imread(image)\n",
    "\n",
    "    # Compute all edgelets.\n",
    "    edgelets1 = compute_edgelets(image)\n",
    "\n",
    "    if algorithm == 'independent':\n",
    "        # Find first vanishing point\n",
    "        vp1 = ransac_vanishing_point(edgelets1, 2000, threshold_inlier=5)\n",
    "        if reestimate:\n",
    "            vp1 = reestimate_model(vp1, edgelets1, 5)\n",
    "\n",
    "        # Remove inlier to remove dominating direction.\n",
    "        edgelets2 = remove_inliers(vp1, edgelets1, 10)\n",
    "\n",
    "        # Find second vanishing point\n",
    "        vp2 = ransac_vanishing_point(edgelets2, 2000, threshold_inlier=5)\n",
    "        if reestimate:\n",
    "            vp2 = reestimate_model(vp2, edgelets2, 5)\n",
    "    elif algorithm == '3-line':\n",
    "        focal_length = None\n",
    "        vp1, vp2 = ransac_3_line(edgelets1, focal_length,\n",
    "                                 num_ransac_iter=3000, threshold_inlier=5)\n",
    "    else:\n",
    "        raise KeyError(\n",
    "            \"Parameter 'algorithm' has to be one of {'3-line', 'independent'}\")\n",
    "\n",
    "    # Compute the homography and warp\n",
    "    warped_img = compute_homography_and_warp(image, vp1, vp2,\n",
    "                                             clip_factor=clip_factor)\n",
    "\n",
    "    return warped_img\n",
    "image = cv2.imread('./fd_jpg/IMG_9129.jpg',0)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "edgelets1 = compute_edgelets(image)\n",
    "vis_edgelets(image, edgelets1) # Visualize the edgelets\n",
    "\n",
    "vp1 = ransac_vanishing_point(edgelets1, num_ransac_iter=2000,\n",
    "                             threshold_inlier=5)\n",
    "vp1 = reestimate_model(vp1, edgelets1, threshold_reestimate=5)\n",
    "vis_model(image, vp1) # Visualize the vanishing point model\n",
    "\n",
    "edgelets2 = remove_inliers(vp1, edgelets1, 10)\n",
    "vp2 = ransac_vanishing_point(edgelets2, num_ransac_iter=2000,\n",
    "                             threshold_inlier=5)\n",
    "\n",
    "print(vp1)\n",
    "vp2 = reestimate_model(vp2, edgelets2, threshold_reestimate=5)\n",
    "vis_model(image, vp2) # Visualize the vanishing point model\n",
    "\n",
    "print(vp2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "795d64637b038ec5b9d633d83f1d21b6260299cb78d52f8f073978f8c6b76550"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
