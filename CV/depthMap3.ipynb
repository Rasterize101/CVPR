{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument 'minDisparity' is required to be an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jitbh\\OneDrive\\Documents\\GitHub\\CVPR\\depthMap3.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=215'>216</a>\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(minDisparity \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=216'>217</a>\u001b[0m     numDisparities \u001b[39m=\u001b[39m num_disp,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=217'>218</a>\u001b[0m     blockSize \u001b[39m=\u001b[39m \u001b[39m12\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=222'>223</a>\u001b[0m     speckleWindowSize \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=223'>224</a>\u001b[0m     speckleRange \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=226'>227</a>\u001b[0m \u001b[39mprint\u001b[39m(args[\u001b[39m\"\u001b[39m\u001b[39mminDisparity\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=228'>229</a>\u001b[0m stereo \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49mStereoSGBM_create(args)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=229'>230</a>\u001b[0m disparity \u001b[39m=\u001b[39m stereo\u001b[39m.\u001b[39mcompute(img1_gray,img2_gray)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jitbh/OneDrive/Documents/GitHub/CVPR/depthMap3.ipynb#ch0000000?line=231'>232</a>\u001b[0m sigma \u001b[39m=\u001b[39m \u001b[39m1.8\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'minDisparity' is required to be an integer"
     ]
    }
   ],
   "source": [
    "# Start writing code here...\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# dist = np.load('cam_dist.npy',allow_pickle=True)\n",
    "# mtx = np.load('mtx.npy',allow_pickle=True)\n",
    "# newcameramtx = np.load('newcameramtx.npy',allow_pickle=True)\n",
    "\n",
    "# with open('cam_roi.pkl', 'rb') as f: \n",
    "#\troi = pickle.load(f)\n",
    "\n",
    "#def undistort_img(img):\n",
    "# \timg = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "#\tx, y, w, h = roi\n",
    "#\treturn img[y : y + h, x : x + w]\n",
    "\n",
    "\n",
    "img1_big = (cv.imread(r'C:\\Users\\jitbh\\OneDrive\\Desktop\\DSC_0714.jpg')) # queryImage\n",
    "img2_big = (cv.imread(r'C:\\Users\\jitbh\\OneDrive\\Desktop\\DSC_0715.jpg')) # trainImage\n",
    "img1 = img1_big#cv.resize(img1_big, (1368, 912))\n",
    "img2 = img2_big#cv.resize(img2_big, (1368, 912))\n",
    "\n",
    "def drawMatches(img1, kp1, img2, kp2, matches, color=None):\n",
    "    \"\"\"Draws lines between matching keypoints of two images.\n",
    "    Keypoints not in a matching pair are not drawn.\n",
    "    Places the images side by side in a new image and draws circles\n",
    "    around each keypoint, with line segments connecting matching pairs.\n",
    "    You can tweak the r, thickness, and figsize values as needed.\n",
    "    Args:\n",
    "        img1: An openCV image ndarray in a grayscale or color format.\n",
    "        kp1: A list of cv2.KeyPoint objects for img1.\n",
    "        img2: An openCV image ndarray of the same format and with the same\n",
    "        element type as img1.\n",
    "        kp2: A list of cv2.KeyPoint objects for img2.\n",
    "        matches: A list of DMatch objects whose trainIdx attribute refers to\n",
    "        img1 keypoints and whose queryIdx attribute refers to img2 keypoints.\n",
    "        color: The color of the circles and connecting lines drawn on the images.\n",
    "        A 3-tuple for color images, a scalar for grayscale images.  If None, these\n",
    "        values are randomly generated.\n",
    "    \"\"\"\n",
    "    # We're drawing them side by side.  Get dimensions accordingly.\n",
    "    # Handle both color and grayscale images.\n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))\n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 7\n",
    "    if color:\n",
    "        c = color\n",
    "    for m in matches:\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color:\n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = ( int (c [ 0 ]), int (c [ 1 ]), int (c [ 2 ]))\n",
    "\n",
    "\n",
    "        # So the keypoint locs are stored as a tuple of floats.  cv2.line(), like most other things,\n",
    "        # wants locs as a tuple of ints.\n",
    "\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv.line(new_img, end1, end2, c, thickness)\n",
    "        cv.circle(new_img, end1, r, c, thickness)\n",
    "        cv.circle(new_img, end2, r, c, thickness)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(new_img)\n",
    "    plt.show()\n",
    "\n",
    "#Then using SIFT method\n",
    "\n",
    "# img1 = cv.imread('box.png',cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "# img2 = cv.imread('box_in_scene.png',cv.IMREAD_GRAYSCALE) # trainImage\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "# BFMatcher with default params\n",
    "bf = cv.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2,k=2)\n",
    "# Apply ratio test\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.35*n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "# for x in [good[20]] + [good[3]] + [good[34]] + [good[64]] + [good[17]] + [good[13]] + [good[56]] + [good[101]]:\n",
    "for x in good:\n",
    "    pts1.append(list(np.round(kp1[x.queryIdx].pt).astype(int)))\n",
    "    pts2.append(list(np.round(kp2[x.trainIdx].pt).astype(int)))\n",
    "\n",
    "# print(pts1)\n",
    "\n",
    "# cv.drawMatchesKnn expects list of lists as matches.\n",
    "# img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "# drawMatches(img1, kp1, img2, kp2, [good[20]] + [good[3]] + [good[34]] + [good[64]] + [good[17]] + [good[13]] + [good[56]] + [good[101]], color=None)\n",
    "# plt.imshow(img3),plt.show()\n",
    "\n",
    "#\n",
    "# #images 9125 and 9127\n",
    "# img1 = cv.imread('./fd_jpg/IMG_9125.jpg')\n",
    "# img1 = cv.resize(img1, (1368, 912))\n",
    "# pts1 = [[409,212], [412,359], [470,498], [715,461], [688,560], [997,268], [1168,192], [1171,339]]\n",
    "#\n",
    "# img2 = cv.imread('./fd_jpg/IMG_9127.jpg')\n",
    "# img2 = cv.resize(img2, (1368, 912))\n",
    "# pts2 = [[190,191], [197,364], [231,526], [648,461], [647,575], [676,251], [900,166], [903,316]]\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# #corresponding points from image 1 and image 2\n",
    "\n",
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "\n",
    "# print(pts1,pts2)\n",
    "F, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "# print(F)\n",
    "# We select only inlier points\n",
    "pts1 = pts1[mask.ravel()==1]\n",
    "pts2 = pts2[mask.ravel()==1]\n",
    "#\n",
    "#\n",
    "# #Drawing the epipolar lines\n",
    "#\n",
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    # print(img1.shape)\n",
    "    r,c,_ = img1.shape\n",
    "    # img1 = cv.cvtColor(img1,cv.COLOR_GRAY2BGR)\n",
    "    # img2 = cv.cvtColor(img2,cv.COLOR_GRAY2BGR)\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv.line(img1, (x0,y0), (x1,y1), color,4)\n",
    "        img1 = cv.circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = cv.circle(img2,tuple(pt2),5,color,-1)\n",
    "    return img1,img2\n",
    "#\n",
    "#\n",
    "#\n",
    "# Find epilines corresponding to points in right image (second image) and\n",
    "\n",
    "# drawing its lines on left image\n",
    "lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "# img5,img6 = drawlines(img1,img2,lines1[:20],pts1[:20],pts2[:20])\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "\n",
    "# drawing its lines on right image\n",
    "lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "# img3,img4 = drawlines(img2,img1,lines2[:20],pts2[:20],pts1[:20])\n",
    "\n",
    "#\n",
    "# plt.subplot(121),plt.imshow(img5)\n",
    "# plt.subplot(122),plt.imshow(img3)\n",
    "# plt.show()\n",
    "#\n",
    "#\n",
    "# #using the fundamental matrix calculated in task 4_2 (shown above)\n",
    "#\n",
    "# Stereo rectification (uncalibrated variant)\n",
    "# Adapted from: https://stackoverflow.com/a/62607343\n",
    "h1, w1,_ = img1.shape\n",
    "h2, w2,_ = img2.shape\n",
    "_, H1, H2 = cv.stereoRectifyUncalibrated(\n",
    "    np.float32(pts1), np.float32(pts2), F, imgSize=(w1, h1)\n",
    ")\n",
    "#\n",
    "#What we get back are the transformations encoded by the homography matrices H1 and H2\n",
    "\n",
    "# Undistort (rectify) the images and save them\n",
    "# Adapted from: https://stackoverflow.com/a/62607343\n",
    "img1_rectified = cv.warpPerspective(img1, H1, (w1, h1))\n",
    "img2_rectified = cv.warpPerspective(img2, H2, (w2, h2))\n",
    "# cv.imwrite(\"rectified_1.png\", img1_rectified)\n",
    "# cv.imwrite(\"rectified_2.png\", img2_rectified)\n",
    "\n",
    "# Draw the rectified images\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "# axes[0].imshow(img2_rectified, cmap=\"gray\")\n",
    "# axes[1].imshow(img1_rectified, cmap=\"gray\")\n",
    "# axes[0].axhline(250)\n",
    "# axes[1].axhline(250)\n",
    "# axes[0].axhline(450)\n",
    "# axes[1].axhline(450)\n",
    "# plt.suptitle(\"Rectified images\")\n",
    "# # plt.savefig(\"rectified_images.png\")\n",
    "# plt.show()\n",
    "\n",
    "img2_gray = cv.cvtColor(img2_rectified, cv.COLOR_BGR2GRAY)\n",
    "img1_gray = cv.cvtColor(img1_rectified, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "window_size = 3\n",
    "min_disp = 0\n",
    "num_disp = 110-min_disp\n",
    "\n",
    "args = dict(minDisparity = 0,\n",
    "    numDisparities = num_disp,\n",
    "    blockSize = 12,\n",
    "    P1 = 8*3*window_size**2,\n",
    "    P2 = 32*3*window_size**2,\n",
    "    disp12MaxDiff = 1,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32)\n",
    "\n",
    "\n",
    "print(args[\"minDisparity\"])\n",
    "\n",
    "stereo = cv.StereoSGBM_create(args)\n",
    "disparity = stereo.compute(img1_gray,img2_gray)\n",
    "\n",
    "sigma = 1.8\n",
    "lmbda = 1000.0\n",
    "\n",
    "left_matcher = cv.StereoSGBM_create(**args)\n",
    "right_matcher = cv.ximgproc.createRightMatcher(left_matcher)\n",
    "left_disp = left_matcher.compute(img1_gray, img2_gray)\n",
    "right_disp = right_matcher.compute(img2_gray,img1_gray)\n",
    "\n",
    "# Now create DisparityWLSFilter\n",
    "wls_filter = cv.ximgproc.createDisparityWLSFilter(left_matcher)\n",
    "wls_filter.setLambda(lmbda)\n",
    "wls_filter.setSigmaColor(sigma)\n",
    "filtered_disp = wls_filter.filter(left_disp, img1_gray, disparity_map_right=right_disp)\n",
    "\n",
    "plt.imshow(filtered_disp,cmap = 'plasma')\n",
    "# plt.imshow(img1_rectified)\n",
    "# plt.show()\n",
    "plt.colorbar(shrink=.7)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(disparity,cmap = 'plasma')\n",
    "plt.colorbar(shrink=.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ff72952f7105dbc143c687dc5efeb2508a059813f4ff275186678ada68472a2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
